---
title: "Análisis de datos de comercio electrónico"
author: 
  - Allan Martínez
  - Brenda Fonseca
  - Lindey Carvajal
  - Patrick Santamaría
date: "20 de julio de 2023"
always_allow_html: yes
output:
  rmdformats::downcute:
    fig_width: 12
    fig_height: 6
    use_bookdown: true
    number_sections: false
editor_options:
  chunk_output_type: console
---

# Cargar paquetes

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# Carga de paquetes ------------------------------------------------------------
library(tidyverse)
library(tidymodels)
library(janitor)
library(gt)
library(kernlab)
library(xgboost)
library(PerformanceAnalytics)
library(RColorBrewer)
library(ggplot2)
library(gridExtra)
library(grid)
library(DT)
library(vip)

# Opciones ---------------------------------------------------------------------
options(scipen = 999)

# Funciones --------------------------------------------------------------------
cuadro_distribucion <- function(datos, variable, nombre_variable) {
  
  datos %>% 
   tabyl(!!variable) %>% 
  adorn_totals() %>% 
  set_names(c(nombre_variable, "Cantidad de clientes",
              "Porcentaje")) %>% 
  gt() %>% 
  fmt_percent(
    columns = 3,
    decimals = 1
  ) %>% 
  fmt_number(
    columns = 2,
    sep_mark = " ",
    decimals = 0
  ) %>% 
  tab_header(
    title = paste("Distribución de frecuencia absoluta y porcentual para la variable", tolower(nombre_variable))
  )
  
  
}
```

# Diccionario de datos

```{r}
tibble(
   id_variable = c("ID", "warehouse_block", "mode_of_shipment",
               "customer_care_calls", "customer_rating", "cost_of_the_product",
               "prior_purchases", "product_importance", "gender",
               "discount_offered", "weight_in_gms", "reached_on_time"),
  variable = c("ID", "Bloque de almacén", "Modo de envío",
               "Llamadas de atención al cliente", 
               "Calificación del cliente", "Costo del producto",
               "Compras previas", "Importancia del producto", "Género",
               "Descuento ofrecido", "Peso", "Entregado a tiempo"),
  descripcion = c("ID del cliente", 
                  "La empresa tiene un gran almacén que se divide en bloques como A, B, C, D, E.",
                  "La empresa envía los productos de varias maneras, como barco, vuelo y carretera.",
                  "Número de llamadas realizadas a partir de consulta por consulta del envío.",
                  "La empresa ha calificado a cada cliente. 1 es el más bajo (peor), 5 es el más alto (mejor).",
                  "Costo del producto en dolares estadounidenses.",
                  "Número de compras previas del cliente",
                  "La empresa ha categorizado el producto en varios parámetros, como bajo, medio, alto.",
                  "Género del cliente, puede ser masculino o femenino.",
                  "Descuento ofrecido en ese producto específico.",
                  "Peso en gramos del producto.",
                  "Es la variable objetivo, donde 1 indica que el producto NO ha llegado a tiempo y 0 indica que ha llegado a tiempo.")
) %>% 
  set_names(c("ID de la variable", "Nombre de variable",
              "Descripcion de la variable")) %>% 
  gt() %>% 
  tab_header(
    title = "Diccionario de variables de datos de envio de empresa de comercio electrónico"
  ) 
```

# Lectura de datos

```{r}
datos <- read_csv("datos/Train.csv") %>% 
  clean_names() %>% 
  rename(reached_on_time = reached_on_time_y_n) %>% 
  mutate(across(.cols = where(is.character),
                .fns = as.factor),
         reached_on_time = as.factor(reached_on_time)) 
```

# Exploración inicial

Primero se verifica que tan des balanceadas están las clases:

```{r}
datos %>% 
  cuadro_distribucion("reached_on_time", "Entregado a tiempo")
```

Se observa que las clases no están demasiado des balanceadas, sin embargo, para asegurar la representación de cada una de las clases se utilizará la estratificación a la hora de escoger el conjunto de datos de entrenamiento y de prueba en la validación cruzada, con el fin de que ambas clases queden representadas en ambos conjuntos de datos y en los distintos pliegues del plan de validación cruzada.

Luego de esto se realiza una exploración rápida de las variables numéricas y sus correlaciones:

```{r}
datos %>% 
  select(where(is.numeric), -id) %>% 
  cor(method = "pearson") %>% 
  chart.Correlation()
```

No se observan correlaciones mayores a 0.52 o menores a -0.51.

Adicionalmente, se explorará la distribución de categorías de las variables que son factores. Iniciando con bloque de almacén:

```{r}
datos %>% 
  cuadro_distribucion("warehouse_block", "Bloque de almacén")
```

Seguidamente el modo de envío:

```{r}
datos %>% 
  cuadro_distribucion("mode_of_shipment", "Modo de envío")
```

La importancia del producto:

```{r}
datos %>% 
  cuadro_distribucion("product_importance", "Importancia del producto")
```

Y finalmente el género:

```{r}
datos %>% 
  cuadro_distribucion("gender", "Género")
```

Se procede a determinar la distribución de las variables de acuerdo con la variable objetivo ("Entregado a Tiempo")

Primero se analizan las variables categóricas:
```{r}
pilas <- function(datos, i, nombre, Y, Y_nombre) {
datos %>% 
    dplyr::group_by({{Y}}, {{i}}) %>% 
  count() %>%  
  ggplot(mapping = aes(x = reorder({{i}}, n), y = n, fill = {{Y}})) +
  geom_col(position = "dodge")   + 
    scale_fill_manual(values = brewer.pal(n = 8, name = "Set3"))+
  theme_minimal()+
  theme(legend.position = "top",
        axis.text.x = element_text(angle = 45, hjust = 1))+
    labs(x=nombre, y="Cantidad", fill=Y_nombre)
}

p1 = pilas(datos, warehouse_block , "Bloque de Almacén", reached_on_time, "Entregado a Tiempo")
p3 = pilas(datos, mode_of_shipment, "Modo de Envío",reached_on_time,"Entregado a Tiempo")
p4 = pilas(datos, product_importance , "Importancia del Producto",reached_on_time,"Entregado a Tiempo")
p5 = pilas(datos, gender, "Género",reached_on_time,"Entregado a Tiempo")
grid.arrange(
  p1,
  p3,
  p4,
  p5,
  nrow = 2,
top = "Análisis descritiptivo de las variables categóricas con respecto a la variable objetivo")
```
Al analizar las variables categóricas con respecto a los valores de la variable objetivo se encuentra que todas las estudiadas tiene un comportamiento similar: de esta manera, la categoría Entregado a Tiempo (0) siempre es menor en cualquieras de los factores de las varibles analizadas. Lo cual concuerda con lo analizado al inicio en donde se vio que la categoria 0 es menor que la categoría 1 (40.3% vs 59.7%).

Segundo se analizan las variables numéricas:
```{r}
gviolin <- function(data, predictoras, nombre_predictoras,Y, Y_nombre) {
    ggplot(mapping = aes(x = {{Y}}, y = {{predictoras}}, fill = {{Y}} ), data = data) +
    geom_violin(show.legend = FALSE) +
    geom_boxplot(width = 0.1, show.legend = FALSE)  + 
    scale_fill_manual(values = brewer.pal(n = 8, name = "Set3"))+
    theme(legend.position = "none") +
    theme_minimal()+
    labs(y=nombre_predictoras, x=Y_nombre)
}

v1 <- gviolin(datos, customer_care_calls,"Llamadas de atención al cliente",reached_on_time, "Entregado a Tiempo")
v3 <- gviolin(datos, customer_rating,"Calificación del Cliente",reached_on_time, "Entregado a Tiempo")
v4 <- gviolin(datos, cost_of_the_product,"Costo del Producto",reached_on_time, "Entregado a Tiempo")
v5 <- gviolin(datos, prior_purchases,"Compras Previas",reached_on_time, "Entregado a Tiempo")
v6 <- gviolin(datos, weight_in_gms, "Peso",reached_on_time, "Entregado a Tiempo")
v7 <- gviolin(datos, discount_offered, "Descuento Ofrecido",reached_on_time, "Entregado a Tiempo")
grid.arrange(
  v1,
  v3,
  v4,
  v5,
  v6,
  v7,
  nrow = 3,
top = "Análisis descritiptivo de las variables numéricas con respecto a la variable objetivo")
```
Se crea además una tabla resumen por variable según la categoría de la variable objetivo que ayude a verificar los resultados obtenidos de lo gráficos:
```{r}
resumen <- function(data, predictora,Y){
data %>%
  group_by({{Y}}) %>%
  summarise(min = min({{predictora}}),
            q1 = quantile({{predictora}}, 0.25),
            median = median({{predictora}}),
            mean = round(mean({{predictora}}), 2),
            q3 = quantile({{predictora}}, 0.75),
            max = max({{predictora}}))
    
}


r1 <- resumen(datos, customer_care_calls, reached_on_time)
r2 <- resumen(datos, customer_rating, reached_on_time)
r3 <- resumen(datos, cost_of_the_product, reached_on_time)
r4 <- resumen(datos, prior_purchases, reached_on_time)
r5 <- resumen(datos, weight_in_gms, reached_on_time)
r6 <- resumen(datos, discount_offered, reached_on_time)
rsumary <- rbind(r1, r2, r3, r4, r5, r6)
rsumary <- rsumary %>% 
  rename("Entregado a Tiempo" = 1)
rsumary <- rsumary %>% 
  mutate(Variable = rep(
    c(
      "Llamadas de atención al cliente",
      "Calificación del Cliente",
      "Costo del Producto",
      "Compras Previas",
      "Peso",
      "Descuento Ofrecido"
    ),
    each = 2
  )) %>% 
  select(8, 1:7)

datatable(
  head(rsumary, 20),
  caption = "Tabla Resumen para las variables numéricas de acuerdo a las categorías de la variable ojetivo",
  options = list(pageLength = 10,
                 scrollX = TRUE)
)
```

Con base en los gráficos violines y en la tabla generados, se observa que las categorías de la variable objetivo se comportan de manera muy similar en las variables:Llamadas de atención al cliente, calificación del cliente, costo del producto y compras previas, ya que sus boxplots (y por ende sus características de la tabla: media, variancia, mínimos y máximos) y su distribución de densidad entre los valores se comportan de manera parecida.
Por otro lado, las variables de peso y descuento ofrecido se comportan de manera diferente, de esta forma:
- Peso: Los productos que no han llegado a tiempo (1) normalmente se concentran entre aquellos que pesan menos de 2000. Mientras que los productos que han llegado a tiempo (0) se concentran entre aquellos que pesan entre 4000 y 6000 (con algunos datos extremos cuyos valores son menores a 2000)
- Descuento Ofrecido: Los productos que han llegado a tiempo (0) son aquellos para los cuales se ofrecio un descuento de menos de 10. Mientras que los productos que no han llegado a tiempo se encuentran mas distribuidos a lo largo del rango de descuento 0-60 (aunque tienen una concentración de densidad un poco mayor en menos de 10)

# Modelado

Para la parte de modelado se crearán modelos de clasificación, donde la variable respuesta es si el producto fue entregado a tiempo o no, y las variables predictoras, se utilizarán todas las exploradas, ya que interesa tener la mayor capacidad de clasificación satisfactoria.

Para lo modelos de clasificiación se pondrán a competir 3 variaciones de las máquinas de soporte vectorial (SVM), utilizando 3 funciones de núcleo distintas, la lineal, la polinomial y la radial. Adicionalmente como cuarto modelo se realizará un ensamble de árboles que es un método más reciente, potente y ampliamente utilizado que se llama XG Boost.

Las SVM lineales intentan separar las clases (en este caso si el prooducto se entregó a tiempo o no en) en una línea recta o plano, mientras que la función de núcleo polinomial y radial permite realizar separaciones de las clases no lineales más complejas, en donde la radial es capaz de hacer separaciones no lineales más complejas, ya que la función permite capturar estructuras más intrincadas en los datos, así que es especialmente útil cuando no se conoce la forma exacta de separación de los datos, como el presente caso.

Por otro lado, XG Boost es un algoritmo de clasificación que se basa en el refuerzo de gradientes. Este combina múltiples modelos más débiles (generalmente árboles de decisión) para formar un modelo más fuerte y preciso. El objetivo del refuerzo de gradientes es mejorar iterativamente un modelo, agregando nuevos modelos que se centren en los errores cometidos por los modelos anteriores.

Para realizar los modelos se utilizarán las diferentes librerías contenidas dentro el paquete de tidymodels a continuación:

## Definición de la receta

Se plantea la receta general que se utilizara en todos los modelos, para el caso de las variables que son factores transformarán en variables dummy, y en el caso de las variables numéricas se realizará el paso de normalización de las mismas, con el fin de que las unidades de medida de las distintas variables no afecten los resultados del modelo. Se define la receta a continuación:

```{r}
receta <- recipe(reached_on_time ~ ., datos %>% 
                   select(-id)) %>% 
  step_dummy(all_factor_predictors()) %>% 
  step_normalize(all_numeric_predictors())
```

Para el ajuste de los modelos se realizará una calibración de parámetros, utilizando distintas combinaciones de los mismos para obtener la combinación más óptima. Esto se realizará con un plan de validación cruzada de 10 pliegues, que utilizará la estratificación de tidymodels para asegurar la representación de ambas clases en los 10 pliegues:

```{r}
set.seed(17)
plan_vc <- vfold_cv(data = datos %>% 
                      select(-id), 
                    v = 10,
                    strata = reached_on_time)
```

## Definición de modelos

Posterior a ello con el paquete parsnip, se definen los modelos antes mencionados y los parámetros que se calibrarán. En el caso de máquinas de soporte vectorial lineal se calibrará la función de costo (cost), en el polinomial adicionalmente se calibrará el grado del polinomio (degree) y el factor de escala (scale_factor) aplicado a los predictores, y finalmente para la función radial la desviación estándar del núcleo radial (rbf_sgima).

En el caso de XG Boost se calibrará el número de variables predictoras aleatorias (mtry) que se utilizarán en los árboles del ensamble, el número mínimo de observaciones para los nodos hoja (min_n) y la cantidad de árboles (trees) del ensamble.

```{r}
modelo_svm_lin <- svm_linear() %>% 
  set_engine(engine = "kernlab") %>%
  set_mode("classification") %>% 
  set_args(cost = tune())

modelo_svm_poly <- svm_poly() %>% 
  set_engine(engine = "kernlab") %>%
  set_mode("classification") %>% 
  set_args(cost = tune(),
           degree = tune(),
           scale_factor = tune())

modelo_svm_rbf <- svm_rbf() %>% 
  set_engine(engine = "kernlab") %>%
  set_mode("classification") %>% 
  set_args(cost = tune(),
           rbf_sigma = tune())

modelo_xg <- boost_tree() %>% 
  set_engine(engine = "xgboost") %>%
  set_mode("classification") %>% 
  set_args(mtry = tune(),
           min_n = tune(),
           trees = tune())
```

## Definición de grilla o combinaciones de parámetros

A continuación se definen las combinaciones de parámetros que serán probados en cada uno de los modelos. En el caso de la SVM lineal se utilzarán 125 combinaciones de la función de costo:

```{r}
grilla_svm_lin <- grid_regular(cost(),
                               levels = 125)

grilla_svm_lin %>% 
  datatable(caption = "Combinaciones de parámetros para el modelo de SVM lineal",
            options = list(
              pageLength = 10, 
              scrollX = TRUE,
              lengthChange = FALSE))
```

Para las SVM polinomial se utilizarán 125 combinaciones de una grilla regular en base a los 3 hiperparámetros que se calibrarán, dichas combinaciones se muestran a continuación:

```{r}
grilla_svm_poly <- grid_regular(cost(),
                                degree(),
                                scale_factor(),
                                levels = 5)

grilla_svm_poly %>% 
  datatable(caption = "Combinaciones de parámetros para el modelo de SVM polinomial",
            options = list(
              pageLength = 10, 
              scrollX = TRUE,
              lengthChange = FALSE))
```

Para las SVM radiales se utilizarán 121 combinaciones entre los dos hiperparámetros a calibrar:

```{r}
grilla_svm_rbf <- grid_regular(cost(),
                               rbf_sigma(),
                               levels = 11)

grilla_svm_rbf %>% 
  datatable(caption = "Combinaciones de parámetros para el modelo de SVM radial",
            options = list(
              pageLength = 10, 
              scrollX = TRUE,
              lengthChange = FALSE))
```

Y finalmente para XG Boost por medio de otra grilla regular, se evaluarán 125 combinaciones entre los 3 hiperparámetros a calibrar, utilizando una grilla regular:

```{r}
grilla_xg <- grid_regular(mtry(range = c(1, 10)),
                          min_n(),
                          trees(),
                          levels = 5)

grilla_xg %>% 
  datatable(caption = "Combinaciones de parámetros para el modelo de XG Boost",
            options = list(
              pageLength = 10, 
              scrollX = TRUE,
              lengthChange = FALSE))
```

## Ajuste de hiperparámetros

Para realizar el ajuste de los hiperparámetros se definen los flujos de trabajo del paquete workflows y se procede a aplicar el plan de validación cruzada a las grillas definidas anteriormente, con el fin de obtener las métricas de precisión y de ROC AUC para determinar el desempeño del modelo en las distintas combinaciones:

```{r}
flujo_trabajo_svm_lin <- workflow() %>%
  add_recipe(receta) %>% 
  add_model(modelo_svm_lin) 

flujo_trabajo_svm_poly <- workflow() %>%
  add_recipe(receta) %>% 
  add_model(modelo_svm_poly) 

flujo_trabajo_svm_rbf <- workflow() %>%
  add_recipe(receta) %>% 
  add_model(modelo_svm_rbf) 

flujo_trabajo_xg <- workflow() %>%
  add_recipe(receta) %>% 
  add_model(modelo_xg) 


if (file.exists("datos/svm_lin.Rdata")) {
  load("datos/svm_lin.Rdata")
} else {
  ajuste_hiperparametros_svm_lin <-
    flujo_trabajo_svm_lin %>%
    tune_grid(
      resamples = plan_vc,
      grid = grilla_svm_lin,
      metrics = metric_set(accuracy, roc_auc),
      control = control_grid(verbose = TRUE))
  
  save(ajuste_hiperparametros_svm_lin, file = "datos/svm_lin.Rdata")
}


if (file.exists("datos/svm_poly.Rdata")) {
  load("datos/svm_poly.Rdata")
} else {
  ajuste_hiperparametros_svm_poly <-
    flujo_trabajo_svm_poly %>%
    tune_grid(
      resamples = plan_vc,
      grid = grilla_svm_poly,
      metrics = metric_set(accuracy, roc_auc),
      control = control_grid(verbose = TRUE))
  
  save(ajuste_hiperparametros_svm_poly, file = "datos/svm_poly.Rdata")
}


if (file.exists("datos/svm_rbf.Rdata")) {
  load("datos/svm_rbf.Rdata")
} else {
  ajuste_hiperparametros_svm_rbf <-
    flujo_trabajo_svm_rbf %>%
    tune_grid(
      resamples = plan_vc,
      grid = grilla_svm_rbf,
      metrics = metric_set(accuracy, roc_auc),
      control = control_grid(verbose = TRUE))
  
  save(ajuste_hiperparametros_svm_rbf, file = "datos/svm_rbf.Rdata")
}

if (file.exists("datos/xgboost.Rdata")) {
  load("datos/xgboost.Rdata")
} else {
  ajuste_hiperparametros_xg <-
    flujo_trabajo_xg %>%
    tune_grid(
      resamples = plan_vc,
      grid = grilla_xg,
      metrics = metric_set(accuracy, roc_auc),
      control = control_grid(verbose = TRUE))
  
  save(ajuste_hiperparametros_xg, file = "datos/xgboost.Rdata")
}


metricas_svm_lin <- ajuste_hiperparametros_svm_lin %>% 
  collect_metrics()

metricas_svm_poly <- ajuste_hiperparametros_svm_poly %>% 
  collect_metrics()

metricas_svm_rbf <- ajuste_hiperparametros_svm_rbf %>% 
  collect_metrics()

metricas_xg <- ajuste_hiperparametros_xg %>% 
  collect_metrics()
```

## Selección de mejor combinación de hiperparámetros

Se decide utilizar la métrica de precisión para determinar cual fué la mejor combinación de parámetros en cada caso, ya que cada combinación de parámetros se ajusta el modelo 10 veces para los 10 distintos pliegues de la validación cruzada, y se obtiene la precisión promedio de esos 10 ajustes. A continuación se muestra la mejor combinación de el modelo de SVM lineal basado en la métrica de precisión:

```{r}
mejor_modelo_svm_lin <- ajuste_hiperparametros_svm_lin %>% 
  select_best(metric = "accuracy")

mejor_modelo_svm_lin %>% 
  select(-.config) %>% 
  gt() %>% 
  tab_header(
    title = "Mejor combinacion de parámetros para SVM lineal"
  ) %>% 
  tab_source_note(
    source_note = paste("La precisión del modelo para esta combinación de hiperparámetros fue de", round(mejor_modelo_svm_lin %>% 
                                                                                                     inner_join(metricas_svm_lin %>% 
                                                                                                                  filter(.metric == "accuracy"), by = c("cost")) %>% 
                                                                                                     pull(mean), 3)
    ))
```

Lo mismo para las SVM polinomial:

```{r}
mejor_modelo_svm_poly <- ajuste_hiperparametros_svm_poly %>% 
  select_best(metric = "accuracy")

mejor_modelo_svm_poly %>% 
  select(-.config) %>% 
  gt() %>% 
  tab_header(
    title = "Mejor combinacion de parámetros para SVM polinomial"
  ) %>% 
  tab_source_note(
    source_note = paste("La precisión del modelo para esta combinación de hiperparámetros fue de", round(mejor_modelo_svm_poly %>% 
                                                                                                     inner_join(metricas_svm_poly %>% 
                                                                                                                  filter(.metric == "accuracy"),
                                                                                                                by = c("cost", "scale_factor", "degree")) %>% 
                                                                                                     pull(mean), 3)
    ))
```

Las SVM radial:

```{r}
mejor_modelo_svm_rbf <- ajuste_hiperparametros_svm_rbf %>% 
  select_best(metric = "accuracy")

mejor_modelo_svm_rbf %>% 
  select(-.config) %>% 
  gt() %>% 
  tab_header(
    title = "Mejor combinacion de parámetros para SVM radial"
  ) %>% 
  tab_source_note(
    source_note = paste("La precisión del modelo para esta combinación de hiperparámetros fue de", round(mejor_modelo_svm_rbf %>% 
                                                                                                     inner_join(metricas_svm_rbf %>% 
                                                                                                                  filter(.metric == "accuracy"),
                                                                                                                by = c("cost", "rbf_sigma")) %>% 
                                                                                                     pull(mean), 3)
    ))
```

Y finalmente para el XG Boost:

```{r}
mejor_modelo_xg <- ajuste_hiperparametros_xg %>% 
  select_best(metric = "accuracy")

mejor_modelo_xg %>% 
  select(-.config) %>% 
  gt() %>% 
  tab_header(
    title = "Mejor combinacion de parámetros para XG Boost"
  ) %>% 
  tab_source_note(
    source_note = paste("La precisión del modelo para esta combinación de hiperparámetros fue de", round(mejor_modelo_xg %>% 
                                                                                                     inner_join(metricas_xg %>% 
                                                                                                                  filter(.metric == "accuracy"),
                                                                                                                by = c("trees", "mtry", "min_n")) %>% 
                                                                                                     pull(mean), 3)
    ))
```

## Ajuste del modelo

Una vez seleccionada la mejor combinación de parámetros se ajustan los modelos con dichas combinaciones al conjunto de datos total:

```{r}
flujo_trabajo_svm_lin <- flujo_trabajo_svm_lin %>% 
  finalize_workflow(mejor_modelo_svm_lin)

flujo_trabajo_svm_poly <- flujo_trabajo_svm_poly %>% 
  finalize_workflow(mejor_modelo_svm_poly)

flujo_trabajo_svm_rbf <- flujo_trabajo_svm_rbf %>% 
  finalize_workflow(mejor_modelo_svm_rbf)

flujo_trabajo_xg <- flujo_trabajo_xg %>% 
  finalize_workflow(mejor_modelo_xg)


modelo_svm_lin_entrenado <- flujo_trabajo_svm_lin %>% 
  fit(datos %>% 
        select(-id)) %>% 
  extract_fit_parsnip()

modelo_svm_poly_entrenado <- flujo_trabajo_svm_poly %>% 
  fit(datos %>% 
        select(-id)) %>% 
  extract_fit_parsnip()

modelo_svm_rbf_entrenado <- flujo_trabajo_svm_rbf %>% 
  fit(datos %>% 
        select(-id)) %>% 
  extract_fit_parsnip()

modelo_xg_entrenado <- flujo_trabajo_xg %>% 
  fit(datos %>% 
        select(-id)) %>% 
  extract_fit_parsnip()
```

## Obtención de métricas de desempeño

Con dichos modelos ajustados se obtienen las métricas de desempeño de precisión y ROC AUC de cada uno de los 4 modelos y se comparan los resultados de las mismas en el siguiente cuadro:

```{r}
# Métricas usando validación cruzada
indicadores_svm_lin <- metricas_svm_lin %>% 
  inner_join(mejor_modelo_svm_lin %>% 
               select(-.config), by = c("cost")) %>% 
  select(.metric, mean) %>% 
  mutate(modelo = "Máquinas de soporte lineal") %>% 
  mutate(.metric = case_when(
    .metric == "accuracy"  ~ "Precisión",
    .metric == "roc_auc" ~ "ROC AUC"),
    mean = round(mean, 3)) 

indicadores_svm_poly <- metricas_svm_poly %>% 
  inner_join(mejor_modelo_svm_poly %>% 
               select(-.config), by = c("cost", "degree",
                                        "scale_factor")) %>% 
  select(.metric, mean) %>% 
  mutate(modelo = "Máquinas de soporte polinomial") %>% 
  mutate(.metric = case_when(
    .metric == "accuracy"  ~ "Precisión",
    .metric == "roc_auc" ~ "ROC AUC"),
    mean = round(mean, 3)) 

indicadores_svm_rbf <- metricas_svm_rbf %>% 
  inner_join(mejor_modelo_svm_rbf %>% 
               select(-.config), by = c("cost", "rbf_sigma")) %>% 
  select(.metric, mean) %>% 
  mutate(modelo = "Máquinas de soporte radial") %>% 
  mutate(.metric = case_when(
    .metric == "accuracy"  ~ "Precisión",
    .metric == "roc_auc" ~ "ROC AUC"),
    mean = round(mean, 3))

indicadores_xg <- metricas_xg %>% 
  inner_join(mejor_modelo_xg %>% 
               select(-.config), by = c("mtry", "min_n",
                                        "trees")) %>% 
  select(.metric, mean) %>% 
  mutate(modelo = "XGBoost") %>% 
  mutate(.metric = case_when(
    .metric == "accuracy"  ~ "Precisión",
    .metric == "roc_auc" ~ "ROC AUC"),
    mean = round(mean, 3))
```

La siguiente tabla muestra la comparación de métricas en todos los modelos utilizando validación cruzada y en su estimación final:

```{r}
indicadores_svm_lin %>% 
  bind_rows(indicadores_svm_poly) %>% 
  bind_rows(indicadores_svm_rbf) %>% 
  bind_rows(indicadores_xg) %>% 
  pivot_wider(names_from = ".metric",
              values_from = "mean") %>% 
  arrange(desc(`Precisión`)) %>% 
  #arrange(desc(`ROC AUC`)) %>% 
  rename(Modelo = modelo) %>% 
  gt() %>% 
  tab_header(
    title = "Comparacion de métricas de desempeño entre los modelos ajustados con validación cruzada de 10 pliegues"
  )
```

Se observa que el modelo de XG Boost tuvo un mejor desempeño que las distintas variaciones de función de núcleo de máquinas de soporte vectorial. La precisión del modelo de XG Boost para predecir tanto los casos que se entregan a tiempo, como no a tiempo, es de un 68,3%. 

Una particularidad y ventaja de los ensambles de árboles como XG Boost es que permiten extraer una medida de importancia de las variables del modelo, que se muestra en el siguiente gráfico:

```{r}
modelo_xg_entrenado %>%
  vip(geom = "col", aesthetics = list(fill = "#0EA7B9")) +
  labs(y = "Importancia de la variable",
       title = "Importancia de variables para modelo con algoritmo XG Boost") +
  theme_minimal()
```

Tal y como lo muestra el gráfico anterior, en el modelo de XG Boost la variable que tiene mayor importancia en si el producto se entrega a tiempo o no es el descuento ofrecido, y en un segundo lugar se encuentra la variable de peso en gramos del producto.


